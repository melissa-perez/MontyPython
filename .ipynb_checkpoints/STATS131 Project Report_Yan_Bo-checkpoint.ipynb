{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#            < Breast Cancer Diagnosis Report \\> \n",
    "###         ——       Predict Whether the Cancer is Benign or Malignant \n",
    "####             By Jemma Le, Annie Lee, Melissa Perez, Yan Bo Zeng "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Context and Description of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Background information on the subject and field of study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast cancer is a type of cancer that forms in the cells of the breasts. After skin cancer, breast cancer is the most common cancer diagnosed in women in the United States. Breast cancer can occur in both men and women, but it's far more common in women.\n",
    "\n",
    "Substantial support for breast cancer awareness and research funding has helped create advances in the diagnosis and treatment of breast cancer. Breast cancer survival rates have increased, and the number of deaths associated with this disease is steadily declining, largely due to factors such as earlier detection, a new personalized approach to treatment and a better understanding of the disease.\n",
    "\n",
    "The data explores ten visually assessed\n",
    "characteristics of an FNA sample which are considered relevant to breast cancer diagnosis for diagnosing the stage of breast cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Information about Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Breast Cancer Diagnostic Data Set was created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian, professors at University of Wisconsin in 1992. It was constructed on the demand of building sound statistical models to predict whether a breast tumor is benign, noncancerous, or malignant, cancerous, based on the features of cell nucleus sampled from the breast tumor. According to Dr. Wolberg, this work grew out of his desire to accurately diagnose breast smasses based solely on a Fine Needle Aspiration (FNA). He identified nine visually assessed\n",
    "characteristics of an FNA sample which he considered relevant to diagnosis. A classifier was then constructed using the multi-surface method (MSM) of pattern separation on these nine\n",
    "features that successfully diagnosed 97% of new cases. Later, the resulting dataset was saved and published for free as this Breast Cancer Diagnostic Data Set.\n",
    "\n",
    "There are 10 real-valued features stored in the data set. Each of them was computed from\n",
    "a digitized image of a Fine Needle Aspirate (FNA) of a breast mass. They describe\n",
    "characteristics of the cell nuclei present in the image:\n",
    "1. Radius – mean of distances from center to points on the perimeter\n",
    "2. Texture – standard deviation of gray-scale values\n",
    "3. Perimeter\n",
    "4. Area\n",
    "5. Smoothness – local variation in radius lengths\n",
    "6. Compactness – (perimeter ^ 2 / area) – 1\n",
    "7. Concavity – severity of concave portions of the contour\n",
    "8. Concave Points – number of concave portions of the contour\n",
    "9. Symmetry\n",
    "10. Fractal Dimension – coastline approximation – 1\n",
    "\n",
    "The data set stores the mean, standard error, and “worsts”, which represent the mean of the three\n",
    "largest values of these features computed for each image, resulting in 30 features.\n",
    "\n",
    "The collection of this data set was initiated by Dr. Wolberg in 1990 as Dr. Nick Street’s research team began to the help with the image analysis. The results of the research have been\n",
    "consolidated into a software system known as Xcyt. The data collection process was performed as follows:\n",
    "\n",
    "1. An FNA was taken from the breast mass. This material was then mounted on a microscope slide and stained to highlight the cellular nuclei. A portion of the slide in which the cells are well-differentiated was then scanned using a digital camera and a frame-grabber board.\n",
    "\n",
    "2. Researchers then isolated the individual nuclei using Xcyt. Using a mouse pointer, the user drew the approximate boundary of each nucleus. Using a computer vision approach known as “snakes”, these approximations then converged to the exact nuclear boundaries.\n",
    "\n",
    "3. Once all (or most) of the nuclei had been isolated in this fashion, the program computed values for each of ten characteristics of each nuclei, measuring size, shape and texture. The mean, standard error, and extreme values of these features were computed, resulting in a total of 30 nuclear features for each sample.\n",
    "\n",
    "4. In total, the final data set consists of 569 cases, or observations, and 32 variables including case IDs, whether the case is “Benign” or “Malignant”, and 30 nuclear features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Links to our Presentation Slides and Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slides: [Link to Google Slides](https://docs.google.com/presentation/d/1C6noeayp-B79LJMhSeQ5fK8u8WODBxzudVWoZp4dEdA/edit?usp=sharing)\n",
    "\n",
    "\n",
    "Video:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Explotary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Loading\n",
    "We listed all the libraries we used for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as  np # Linear algebra \n",
    "import pandas as  pd # Data processing \n",
    "import matplotlib.pyplot as plt # Data visualization library\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's read the data into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cancer = pd.read_csv('cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Data Features / Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we started with basic data analysis. Let's look at features of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "Unnamed: 32                0 non-null float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "cancer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data information, we found:\n",
    "\n",
    "1) Column __id__ is an unique identifier for each observation, which cannot be used for classification.\n",
    "\n",
    "2) __Diagnosis__ is our class label, which has two levels -- M (Malignant) and B (Benign)\n",
    "\n",
    "3) __Unnamed: 32__ feature includes NaN so we will need to remove them  \n",
    "\n",
    "Therefore, for further data analysis and data modeling, we will drop these unnecessary features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop  unnecessary features: id and Unnamed: 32 columns\n",
    "cancer = cancer.drop(['id','Unnamed: 32'], axis = 1)\n",
    "\n",
    "# Romove missing values \n",
    "cancer = cancer.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x includes predictors only; excluse the response variabel\n",
    "x = cancer.drop([\"diagnosis\"],axis = 1 ) \n",
    "# y includes our labels and x includes our features\n",
    "y = cancer.diagnosis    # M or B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "x_norm = (x - x.mean()) / (x.std())\n",
    "\n",
    "# Devide the variables into 3 parts based on its function\n",
    "col_mean= x_norm.columns[0:10]\n",
    "col_se = cancer.columns[10:20]\n",
    "col_worst = cancer.columns[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Summary Statistics and the Distributional Shape of Variables in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean           ...             \\\n",
       "count     569.000000              569.000000           ...              \n",
       "mean        0.181162                0.062798           ...              \n",
       "std         0.027414                0.007060           ...              \n",
       "min         0.106000                0.049960           ...              \n",
       "25%         0.161900                0.057700           ...              \n",
       "50%         0.179200                0.061540           ...              \n",
       "75%         0.195700                0.066120           ...              \n",
       "max         0.304000                0.097440           ...              \n",
       "\n",
       "       radius_worst  texture_worst  perimeter_worst   area_worst  \\\n",
       "count    569.000000     569.000000       569.000000   569.000000   \n",
       "mean      16.269190      25.677223       107.261213   880.583128   \n",
       "std        4.833242       6.146258        33.602542   569.356993   \n",
       "min        7.930000      12.020000        50.410000   185.200000   \n",
       "25%       13.010000      21.080000        84.110000   515.300000   \n",
       "50%       14.970000      25.410000        97.660000   686.500000   \n",
       "75%       18.790000      29.720000       125.400000  1084.000000   \n",
       "max       36.040000      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "cancer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: area_mean feature's max value is 2501 and smoothness_mean features' max 0.16340. Therefore, we will need __normalization__ before visualization, feature selection, feature extraction, or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics \n",
    "bening = cancer[cancer[\"diagnosis\"] == \"B\"]\n",
    "malignant =cancer[cancer[\"diagnosis\"] == \"M\"]\n",
    "\n",
    "print(\"variance: \",bening.radius_mean.var())\n",
    "print(\"describe method: \",bening.radius_mean.describe())\n",
    "\n",
    "print(\"variance: \",malignant.radius_mean.var())\n",
    "print(\"describe method: \",malignant.radius_mean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Distributional Shape of Response Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\n",
    "B, M = y.value_counts()\n",
    "print('Number of Benign: ',B)\n",
    "print('Number of Malignant : ',M)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution plot we can see, benign has higher proportion in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Distributional Shape of Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divided the data into 3 features: mean, standard error, and worst so that it helped to have better observations on the plots. We used 3 violin plots by dividing features into 3 groups and each group included 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Col_mean\n",
    "data1 = pd.concat([y,x_norm[col_mean]],axis=1)\n",
    "data1 = pd.melt(data1,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data1,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings: \n",
    "\n",
    "(1) In features like __texture_mean, perimeter_mean, area_mean__ , the median of Malignant and Benign are separated, so they can be potentially good for classification. \n",
    "\n",
    "(2) However, in features like __smoothness_mean, symmetry_mean, fractal_dimension_mean__ feature, the median of Malignant and Benign do not look separated, so they do not give good information for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Col_se\n",
    "data2 = pd.concat([y,x_norm[col_se]],axis=1)\n",
    "data2 = pd.melt(data2,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data2,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "- Most variables are highly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Col_worst\n",
    "data3 = pd.concat([y,x_norm[col_worst]],axis=1)\n",
    "data3 = pd.melt(data3,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data3,split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- __perimeter_worst and area_worst__ are good identifiers for the stage type of breast cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Unusual features or outliers present in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also used box plot to help us understand more about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data1)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data3)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings \n",
    "\n",
    "- While looking at box plots, we notice there are several values that are outliers in each variable. \n",
    "- Those values can be errors or rare events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Potential Relationships in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Relationship Distribution Between Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 joint plots below helped us to compare the relationship between 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot compare 2 features\n",
    "sns.jointplot(cancer.radius_mean,cancer.area_mean,kind=\"regg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings: \n",
    "- The value of Pearson r was 0.99 which indicates that they are strongly correlated. There is a clear linear relationship between radius mean and area mean with some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(cancer.smoothness_worst,cancer.compactness_worst,kind=\"regg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pearson r value for compactness worst and smoothness worst was 0.57 which was not very high. Cloud did not show a clear relationship between smoothness_worst and compactness_worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(cancer.loc[:,'symmetry_worst'], cancer.loc[:,'fractal_dimension_worst'], kind=\"regg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The relationship between symmetry_worst and fractal_dimension_worst is not clear with a Pearson r value of 0.54. We also saw a lot of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between more than 2 distribution\n",
    "sns.set(style=\"white\")\n",
    "df = cancer.loc[:,['radius_worst','perimeter_worst','area_worst']]\n",
    "g = sns.PairGrid(df, diag_sharey=False)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "g.map_upper(plt.scatter)\n",
    "g.map_diag(sns.kdeplot, lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Correlation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to observe all correlation between features, we plotted a heatmap. The green color represented the strongest correlation, and the dark blue represented the weakest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation\n",
    "plt.figure(figsize=(14,14))\n",
    "sns.heatmap(cancer.corr(), cbar = True,  square = True, annot=True, linewidths=.5, fmt= '.1f', cmap = 'winter')\n",
    "plt.title('Correlation Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretations\n",
    "- A correlation map is a huge matrix that includes a lot of numbers. The range of these numbers are from -1 to 1.\n",
    "- The meaning of 1 is that two variables are positively correlated with each other like radius mean and area mean.\n",
    "- The meaning of zero is there is no correlation between variables like radius mean and fractal dimension se.\n",
    "- The meaning of -1 is that two variables are negatively correlated with each other. In the case of radius mean and fractal dimension mean the correlation it -0.3, which indicates negative correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Plot Data\n",
    "Compare the size and shape of the nuclei from malignant samples to the size and shape of the nuclei from benign samples.\n",
    "Healthy cells typically have nuclei with a standard size and shape while cancer cells often have nuclei that are large and misshapen. As such, the size and shape of the nucleus should be a good predictor for whether or not a sample is cancerous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancersk = load_breast_cancer()\n",
    "data = np.c_[cancersk.data, cancersk.target]\n",
    "columns = np.append(cancersk.feature_names, [\"target\"])\n",
    "sizeMeasurements = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "sizeMeasurements = pd.DataFrame(data, columns=columns)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plotOne = sns.FacetGrid(sizeMeasurements, hue=\"target\",aspect=2.5)\n",
    "plotOne.map(sns.kdeplot,'mean area',shade=True)\n",
    "plotOne.set(xlim=(0, sizeMeasurements['mean area'].max()))\n",
    "plotOne.add_legend()\n",
    "plotOne.set_axis_labels('mean area', 'Proportion')\n",
    "plotOne.fig.suptitle('Area vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
    "plt.show()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plotTwo = sns.FacetGrid(sizeMeasurements, hue=\"target\",aspect=2.5)\n",
    "plotTwo.map(sns.kdeplot,'mean concave points',shade= True)\n",
    "plotTwo.set(xlim=(0, sizeMeasurements['mean concave points'].max()))\n",
    "plotTwo.add_legend()\n",
    "plotTwo.set_axis_labels('mean concave points', 'Proportion')\n",
    "plotTwo.fig.suptitle('# of Concave Points vs Diagnosis (Blue = Malignant; Green = Benign)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first plot of mean area and proportion confirmed our prediction that healthy nuclei had a default size and that cancer cells had a wide range of sizes, typically greater than the default size.\n",
    "In addition to being larger than healthy cells, cancer cells were often malformed.\n",
    "\n",
    "- The second plot confirmed our prediction that healthy nuclei were typically circular/elliptical and that cancer cells were malformed and had various concave points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In feature selection, we are going to draw a correlation graph so that we can remove multicollinearity.\n",
    "- Multicollinearity means the columns are dependent on each other and is an interaction we try to avoid.\n",
    "- We will do this analysis for features_mean first, then we will do for others and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into 3 parts based on its category\n",
    "category_mean= cancer.columns[1:11]\n",
    "category_se= cancer.columns[11:20]\n",
    "category_worst=cancer.columns[21:31]\n",
    "\n",
    "corr = cancer[category_mean].corr() \n",
    "plt.figure(figsize=(18,18))\n",
    "sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
    "           cmap= 'copper') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings: \n",
    "\n",
    "1. The radius, parameter, and area are highly correlated as expected from their relationship and from these we will use anyone of them.\n",
    "\n",
    "2. Compactness_mean, concavity_mean and concavepoint_mean are highly correlated so we will choose compactness_mean.\n",
    "\n",
    "3. The selected parameters for use are: perimeter_mean, texture_mean, compactness_mean, symmetry_mean, and smoothness_mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_var = ['texture_mean','perimeter_mean','smoothness_mean','compactness_mean','symmetry_mean']\n",
    "# now these are the variables which will use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split our data into train and test\n",
    "train, test = train_test_split(cancer, test_size = 0.3, random_state=1)# in this our main data is splitted into train and test\n",
    "# we can check their dimension\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train[prediction_var]# taking the training data input \n",
    "train_y=train.diagnosis# This is output of our training data\n",
    "# same we have to do for test\n",
    "test_X= test[prediction_var] # taking test data inputs\n",
    "test_y =test.diagnosis   #output value of test dat\n",
    "X = cancer[prediction_var] # Making data for CV\n",
    "y = pd.get_dummies(cancer[\"diagnosis\"]).M\n",
    "y_test_dum = pd.get_dummies(test_y).M\n",
    "y_train_dum = pd.get_dummies(train_y).M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model I: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=100, random_state=42)# a simple random forest model\n",
    "forest_model.fit(train_X,train_y)# now fit our model for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = forest_model.predict(test_X)# predict for the test data\n",
    "# prediction will contain the predicted value by our model predicted values of dignosis column for test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, prediction))\n",
    "\n",
    "acc_RF = metrics.accuracy_score(prediction,test_y) # to check the accuracy\n",
    "# here we will use accuracy measurement between our predicted value and our test output values\n",
    "print(\"Accuracy for Random Forest: {}\".format(acc_RF)+\"\\n\")\n",
    "\n",
    "cv_prec_RF = cross_val_score(forest_model, X, y, cv=5, scoring=\"precision\")\n",
    "print(\"Precision computed using 5-fold cross-validation: {}\".format(cv_prec_RF)+\"\\n\")\n",
    "\n",
    "RFprecMean = cv_prec_RF.mean()\n",
    "print(\"Mean Precision computed using 5-fold cross-validation: {}\".format(RFprecMean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy for random forest model is 94.15 % which seems good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model II: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1 = LogisticRegression()\n",
    "\n",
    "logit1.fit(train_X, y_train_dum)\n",
    "pred = logit1.predict(test_X)\n",
    "\n",
    "print(classification_report(y_test_dum, pred))\n",
    "\n",
    "acc_logit = metrics.accuracy_score(y_test_dum, pred)\n",
    "print(\"Accuracy for Logistic Regression: {}\".format(acc_logit)+\"\\n\")\n",
    "\n",
    "cv_prec_logit = cross_val_score(logit1, X, y, cv=5, scoring=\"precision\")\n",
    "print(\"Precision computed using 5-fold cross-validation: {}\".format(cv_prec_logit)+\"\\n\")\n",
    "\n",
    "LogitprecMean = cv_prec_logit.mean()\n",
    "print(\"Mean Precision computed using 5-fold cross-validation: {}\".format(LogitprecMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_exp = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(np.exp(logit1.coef_)))], axis = 1)\n",
    "coef_exp.columns = [\"Predictors\", \"Exp Coef\"]\n",
    "print(coef_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model III: Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "param_dist = {\"max_depth\": np.random.randint(1, 6, size=5), \"max_features\": np.random.randint(1, 6, size=5), \"min_samples_leaf\": np.random.randint(1, 6, size=5), \"criterion\": [\"gini\", \"entropy\"]}\n",
    "tree = DecisionTreeClassifier()\n",
    "treecv = RandomizedSearchCV(tree, param_dist, cv=5, random_state=42)\n",
    "\n",
    "treecv.fit(X, y)\n",
    "\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(treecv.best_params_)+\"\\n\")\n",
    "print(\"Best score is {}\".format(treecv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(min_samples_leaf=5, max_features=5, max_depth=4, criterion=\"entropy\")\n",
    "tree2 = DecisionTreeClassifier(min_samples_leaf=5, max_features=5, max_depth=4, criterion=\"entropy\")\n",
    "\n",
    "tree1.fit(train_X, y_train_dum)\n",
    "pred = tree1.predict(test_X)\n",
    "\n",
    "print(classification_report(y_test_dum, pred))\n",
    "\n",
    "acc_tree = metrics.accuracy_score(y_test_dum, pred)\n",
    "print(\"Accuracy for Classification Tree: {}\".format(acc_tree)+\"\\n\")\n",
    "\n",
    "cv_prec_tree = cross_val_score(tree1, X, y, cv=5, scoring=\"precision\")\n",
    "print(\"Precision computed using 5-fold cross-validation: {}\".format(cv_prec_tree)+\"\\n\")\n",
    "\n",
    "TreeprecMean = cv_prec_tree.mean()\n",
    "print(\"Mean Precision computed using 5-fold cross-validation: {}\".format(TreeprecMean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model IV: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is all numerical, the K-Nearest Neighbor approach seemed an appropriate choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .40, random_state=42,stratify=y)\n",
    "#Stratify the split according to the labels so that they are distributed in the training and test sets as they are in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of 6 neighbors is around 90%. Setting neighbors to 6 was an arbitrary choice. The following graph shows training and testing accuracies by number of neighbors from 1 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 20)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Setup a k-NN Classifier with k neighbors: knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the testing error is the lowest at ~ n = 19 neighbors.  Although 92% accuracy is a great benchmark we will take a look at other information, such as the confusion matrix and the classification report. Cross-validation will also be performed to determine the best neighbor setting. Arranging a grid from 1 to 20, the function will search to see which location provides the optimal result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "param_grid={'n_neighbors':np.arange(1,20)}\n",
    "knn=KNeighborsClassifier()\n",
    "knn_cv=GridSearchCV(knn,param_grid,cv=5)\n",
    "knn_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score was 91% at 19 neighbors. We will now run KNN again to verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .40, random_state=42,stratify= y)\n",
    "knn=KNeighborsClassifier(n_neighbors=19)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we see that the confusion matrix reports only 16 Benign misclassifications and 2 Malignant misclassifications. The misclassification rate is 0.08% using the KNN method with 93% precision and a recall & f1-score of 92%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
